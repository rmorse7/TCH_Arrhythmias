{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Pipeline for Random cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you run next block, please make sure you download the Waveform Data folder from Rice Box. Note you only need to download the patient folders which have labelled events associated with them (to save space), which are currently patients: 1, 2, 3, 4, 7 , 8, 13, 14, 15, 16, 17, 18, 19, 20, 22. However make sure to keep all patients within their own folder, and keep all patients together in a Waveform Data folder.\n",
    "\n",
    "### Also, make sure to download the Labelled_Events.xlsx file from the GitHub repo. Save both of these to a place where the local version of this notebook has access, and make sure you know the local paths.\n",
    "\n",
    "### Please also download ECG_feature_extraction.py, ECG_preprocessing.py, PPG_preprocessing.py, data_generator.py and CNN_models.py . The detailed information about these .py files can be found in readme file.\n",
    "\n",
    "### Make sure all of you have all installed packages and they are up to date using the requirements.txt file (pip install -r requirements.txt).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import h5py\n",
    "import pywt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from ECG_feature_extraction import *\n",
    "from ECG_preprocessing import *\n",
    "from PPG_preprocessing import *\n",
    "from os import listdir\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading cwt images for later training deep learning model\n",
    "\n",
    "\n",
    "Three parameters need to be provided for this section:\n",
    "\n",
    "patient_folder_path: the local path of the folder containing all Waveform Data (folder containing folders for each patient)\n",
    "\n",
    "excel_file_path: the local path Labelled__Events.xlsx file\n",
    "\n",
    "save_path: the path of folder where you want to save the \"cwt images\" (these will be used for modelling).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After detrend before wavelet:  [146.67326 167.97446 173.65193 ... 172.30809 172.17563 170.23831]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b00700ae0662>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;31m############# you should modify this line to change these respective paths based on the instructions ##############################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[0mload_cwt_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatient_folder_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'I:/COMP549/data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexcel_file_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'I:/COMP549/events/Labelled_Events.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'I:/COMP549/cwt_features_images_ecg/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-b00700ae0662>\u001b[0m in \u001b[0;36mload_cwt_files\u001b[1;34m(patient_folder_path, excel_file_path, save_path, label_type)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabel_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mload_event_cwt_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpatient_folder_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexcel_file_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexcel_sheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b00700ae0662>\u001b[0m in \u001b[0;36mload_event_cwt_images\u001b[1;34m(save_path, patient_folder_path, excel_file_path, excel_sheet_name, fs)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mppg_denoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPG_denoising\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mppg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[1;31m## extract cwt features for ecg signal and ppg signal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[0mecg_cwt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cwt_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mecg_denoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR_peak_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m129\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindowL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindowR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwavelet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'morl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m                 \u001b[0mppg_cwt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cwt_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mppg_denoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR_peak_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m129\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindowL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindowR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwavelet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'coif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\COMP549\\github_local\\ECG_feature_extraction.py\u001b[0m in \u001b[0;36mcompute_cwt_features\u001b[1;34m(original_signal, R_peak_index, scales, windowL, windowR, wavelet)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The beat length is not correct!!! Please check!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mcurrent_coefffs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cwt_coeffs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrescale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m129\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwavelet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'morl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mwavelet_cofficients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_coefffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mi:\\COMP549\\github_local\\ECG_feature_extraction.py\u001b[0m in \u001b[0;36mcompute_cwt_coeffs\u001b[1;34m(original_signal, rescale, scales, wavelet)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;36m2\u001b[0m\u001b[0md\u001b[0m \u001b[0mcoeffs\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0msegment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     '''\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcwt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_signal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscales\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwavelet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrescale\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mcoefficients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[0mcoefficients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pywt\\_cwt.py\u001b[0m in \u001b[0;36mcwt\u001b[1;34m(data, scales, wavelet, sampling_period, method, axis)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'conv'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint_psi_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;31m# batch convolution via loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconvolve\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mconvolve\u001b[1;34m(a, v, mode)\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'v cannot be empty'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mode_from_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_event_cwt_images(save_path,patient_folder_path,excel_file_path,excel_sheet_name='PJ',fs=240):\n",
    "    '''\n",
    "    load cwt features \n",
    "    input:\n",
    "        save_path: it is the folder path to save these np.array files \n",
    "        patient_folder_path: it is the folder containing different patients data\n",
    "        excel_file_path: the path for labelled event excel\n",
    "        excel_sheet_name: it is the labelled event that you plan to work with. Basically save the same events into a folder call the same name as the excel_sheet_name\n",
    "        fs: sampling frequncy\n",
    "\n",
    "    output:\n",
    "        no return value \n",
    "        but you can check the saved file based on your save_path \n",
    "    '''\n",
    "    labelevent = pd.read_excel(excel_file_path,sheet_name=excel_sheet_name)\n",
    "    count = 1\n",
    "    # save_path = save_path+excel_sheet_name+'/'\n",
    "\n",
    "    for _,record in labelevent.iterrows():\n",
    "\n",
    "        label_record = record.tolist()\n",
    "        patient_id,event_start_time,event_end_time = label_record\n",
    "        patient_file_path = patient_folder_path+'/'+str(int(patient_id))\n",
    "\n",
    "\n",
    "        for block_file in listdir(patient_file_path):\n",
    "\n",
    "            # trying to find the ecg signal and ppg signal during the label event time\n",
    "            block_path = patient_file_path+'/'+block_file\n",
    "            all_signals = h5py.File(block_path, 'r')\n",
    "            signals_keys = set(all_signals.keys())\n",
    "            block_start_time,block_end_time = all_signals['time'][0],all_signals['time'][-1]\n",
    "            if block_start_time <= event_start_time <= event_end_time <= block_end_time:\n",
    "                start_index = int((event_start_time-block_start_time)*fs)\n",
    "                end_index = int((event_end_time-block_start_time)*fs)\n",
    "\n",
    "                #event_time = all_signals['time'][start_index:end_index +1]\n",
    "                ecg, ppg = None, None\n",
    "                if 'GE_WAVE_ECG_2_ID' in signals_keys:\n",
    "                    ecg = all_signals['GE_WAVE_ECG_2_ID'][start_index:end_index +1]\n",
    "                if 'GE_WAVE_SPO2_WAVE_ID' in signals_keys:\n",
    "                    ppg = all_signals['GE_WAVE_SPO2_WAVE_ID'][start_index:end_index +1]\n",
    "                # print(\"loaded ppg: \", ppg)\n",
    "\n",
    "                if ppg is None or ecg is None: continue\n",
    "                # ECG signal preprocessing for denoising and R-peak detection\n",
    "                R_peak_index,ecg_denoise = ecg_preprocessing_final(ecg)  # the location of R_peak during the label event\n",
    "                ppg_denoise = PPG_denoising(ppg)\n",
    "                ## extract cwt features for ecg signal and ppg signal\n",
    "                ecg_cwt = compute_cwt_features(ecg_denoise,R_peak_index,scales = np.arange(1,129),windowL=-240,windowR=240,wavelet = 'morl')\n",
    "                ppg_cwt = compute_cwt_features(ppg_denoise,R_peak_index,scales = np.arange(1,129),windowL=-240,windowR=240,wavelet = 'coif')\n",
    "\n",
    "                if len(ecg_cwt)!=len(ppg_cwt): \n",
    "                    raise Exception(\"The beat length is not correct!!! Please check!\")\n",
    "                if not ecg_cwt or not ppg_cwt: continue\n",
    "\n",
    "                for i in range(len(ecg_cwt)):\n",
    "                    combined = np.stack((ecg_cwt[i],ppg_cwt[i]),axis=-1)\n",
    "                    np.save(save_path+str(count)+'_'+excel_sheet_name,combined)\n",
    "                    # temp = ecg_cwt[i]\n",
    "                    # temp = np.reshape(temp,(128,480,1))\n",
    "                    # np.save(save_path+str(count)+'_'+excel_sheet_name,temp)\n",
    "                    count+=1\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_cwt_files(patient_folder_path,excel_file_path,save_path,label_type= ['PJ','PJRP','PO','PP','PS','PVC']):\n",
    "\n",
    "    '''\n",
    "    Implements function load_event_cwt_images to generate cwt features and then save into a specific folder\n",
    "    Arguments:\n",
    "        patient_folder_path: the path of the folder which save the patients' waveforms\n",
    "        excel_file_path: the path of the excel file which contains the label events\n",
    "        save_path: the folder path to save cwt features\n",
    "        label_types: a default list containing labels\n",
    "\n",
    "    Returns:\n",
    "    no return\n",
    "\n",
    "    '''\n",
    "\n",
    "    for label in label_type:\n",
    "        load_event_cwt_images(save_path,patient_folder_path,excel_file_path,excel_sheet_name=label)\n",
    "\n",
    "\n",
    "############# you should modify this line to change these respective paths based on the instructions ##############################################\n",
    "\n",
    "load_cwt_files(patient_folder_path='I:/COMP549/data',excel_file_path='I:/COMP549/events/Labelled_Events.xlsx',save_path='I:/COMP549/cwt_features_images_ecg/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up the library for deep learning \n",
    "if any error generated at this step, please update the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-dd8c0d460740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# session = tf.Session(config=config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# -------------------  start importing keras module ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# import tensorflow.keras.backend.tensorflow_backend as K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "#from data_generator import get_train_valid_generator\n",
    "#from losses import make_loss, dice_coef_clipped, binary_crossentropy, dice_coef, ceneterline_loss\n",
    "import tensorflow as tf\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "# -------------------------- set gpu using tf ---------------------------\n",
    "# import tensorflow as tf\n",
    "# import time\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = tf.Session(config=config)\n",
    "# -------------------  start importing keras module ---------------------\n",
    "from keras.callbacks import (ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping)\n",
    "# import tensorflow.keras.backend.tensorflow_backend as K\n",
    "from keras.optimizers import Adam\n",
    "from CNN_models import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train the deep learning model\n",
    "\n",
    "### Please provide the following information:\n",
    "\n",
    "EPOCHS: epoch number for training \n",
    "\n",
    "BATCH_SIZE: batch size for training\n",
    "\n",
    "DATA_DIR: the path of folder containing \"cwt images\"\n",
    "\n",
    "LOG_DIR: the path of folder you would like to save the training log\n",
    "\n",
    "VAL_SIZE: the percentage of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape : (None, 32, 120, 32)\n",
      "conv2 shape:  (None, 16, 60, 64)\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 120, 2)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 120, 32)       608       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 30, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 30, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15360)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 30722     \n",
      "=================================================================\n",
      "Total params: 49,826\n",
      "Trainable params: 49,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "got twolayerCNN\n",
      "Fitting model...\n",
      "Epoch 1/20\n",
      "   1/5947 [..............................] - ETA: 0s - loss: 0.6836 - accuracy: 0.5000WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/5947 [..............................] - ETA: 1:03:53 - loss: 0.6557 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.5071s vs `on_train_batch_end` time: 0.7835s). Check your callbacks.\n",
      "  15/5947 [..............................] - ETA: 52:08 - loss: 0.5923 - accuracy: 0.7542"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b8f7b16bcbd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-b8f7b16bcbd3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mcsv_logger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./results/{}_train.log'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_valid_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVAL_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     history = model.fit(x = train_gen, \n\u001b[0m\u001b[0;32m     63\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "##############################Please modify this part      ###############################################\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16#8\n",
    "DATA_DIR = 'I:/COMP549/cwt_features_images_ecg' #I:/COMP549/cwt_features_images'\n",
    "LOG_DIR = \"./log\"\n",
    "VAL_SIZE = 0.15\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "def summarize_diagnostics(history):\n",
    "    # you could use this function to plot the result \n",
    "    fig, ax = plt.subplots(1,2, figsize=(20, 10))\n",
    "    # plot loss\n",
    "    ax[0].set_title('Loss Curves', fontsize=20)\n",
    "    ax[0].plot(history.history['loss'], label='train')\n",
    "    ax[0].plot(history.history['val_loss'], label='test')\n",
    "    ax[0].set_xlabel('Epochs', fontsize=15)\n",
    "    ax[0].set_ylabel('Loss', fontsize=15)\n",
    "    ax[0].legend(fontsize=15)\n",
    "    # plot accuracy\n",
    "    ax[1].set_title('Classification Accuracy', fontsize=20)\n",
    "    ax[1].plot(history.history['accuracy'], label='train')\n",
    "    ax[1].plot(history.history['val_accuracy'], label='test')\n",
    "    ax[1].set_xlabel('Epochs', fontsize=15)\n",
    "    ax[1].set_ylabel('Accuracy', fontsize=15)\n",
    "    ax[1].legend(fontsize=15)\n",
    "\n",
    "def train():\n",
    "    model = twoLayerCNN(input_size=(32,120,2))\n",
    "    #model = VGG(input_shape=(128,480,2))\n",
    "    model.summary()\n",
    "#    model.load_weights(pre_model_path)\n",
    "    # model.compile(optimizer=Adam(lr=3e-4), loss=make_loss('bce_dice'),\n",
    "    #               metrics=[dice_coef, binary_crossentropy, ceneterline_loss, dice_coef_clipped])\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer= Adam(lr=3e-5),\n",
    "              metrics=['accuracy'])\n",
    "    print(\"got twolayerCNN\")\n",
    "    model_name = 'twolayerCNN_ecg-{}'.format(int(time.time()))\n",
    "\n",
    "    if not os.path.exists(\"./results/\"):\n",
    "        os.mkdir('./results')\n",
    "    if not os.path.exists(\"./weights/\"):\n",
    "        os.mkdir('./weights')\n",
    "    save_model_weights = \"./weights/ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.hdf5\"\n",
    "    print('Fitting model...')\n",
    "    start_time = time.time()\n",
    "    tensorboard = TensorBoard(log_dir = LOG_DIR, write_images=True)\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=3, verbose=1, mode='min')\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_model_weights,\n",
    "                            monitor=\"val_loss\",\n",
    "                            mode = \"min\",\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            save_weights_only=True)\n",
    "\n",
    "    csv_logger = CSVLogger('./results/{}_train.log'.format(model_name))\n",
    "    train_gen, valid_gen, num_train, num_valid = get_train_valid_generator(data_dir=DATA_DIR,batch_size=BATCH_SIZE,val_size = VAL_SIZE)\n",
    "    history = model.fit(x = train_gen, \n",
    "                        validation_data=valid_gen,\n",
    "                        epochs=EPOCHS,\n",
    "                        steps_per_epoch=(num_train+BATCH_SIZE-1)//BATCH_SIZE,\n",
    "                        validation_steps=(num_valid+BATCH_SIZE-1)//BATCH_SIZE,\n",
    "                        callbacks=[earlystop, checkpoint, tensorboard, csv_logger])\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Training time(h):\", (end_time - start_time) / 3600)\n",
    "    summarize_diagnostics(history)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
